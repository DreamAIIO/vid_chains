{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from vid_chains.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def load_obj_model(name=\"yolov8n.pt\"):\n",
    "    return YOLO(name)\n",
    "\n",
    "\n",
    "def detect_objects(model, img, stream=True, draw_bbox=False):\n",
    "    res = model(img, stream=stream)\n",
    "    if draw_bbox:\n",
    "        return [{\"boxes\": r.boxes.data.detach().cpu().tolist(), \"img\": r.plot()} for r in res]\n",
    "    return [{\"boxes\": r.boxes.data.detach().cpu().tolist(), \"img\": img} for r in res]\n",
    "\n",
    "\n",
    "def get_width(l):\n",
    "    w = l[2] - l[0]\n",
    "    return w\n",
    "\n",
    "\n",
    "def list_widths(obj):\n",
    "    w = []\n",
    "    for i in range(0, len(obj.get(\"boxes\"))):\n",
    "        l = []\n",
    "        for j in range(0, 6):\n",
    "            l.append(obj.get(\"boxes\")[i][j])\n",
    "        if (\n",
    "            l[5] == 39.0\n",
    "        ):  # very specific test case for bottles so will ignore other objects, will remove this in the future\n",
    "            width = get_width(l)\n",
    "            w.append(width)\n",
    "    return w\n",
    "\n",
    "\n",
    "def centroid(l):\n",
    "    t = []\n",
    "    cx = (l[0] + l[2]) / 2.0\n",
    "    cy = (l[1] + l[3]) / 2.0\n",
    "    t.append(cx)\n",
    "    t.append(cy)\n",
    "    return t\n",
    "\n",
    "\n",
    "def list_centroids(obj):\n",
    "    c = []\n",
    "    for i in range(0, len(obj.get(\"boxes\"))):\n",
    "        l = []\n",
    "        for j in range(0, 4):\n",
    "            l.append(obj.get(\"boxes\")[i][j])\n",
    "        centre = centroid(l)\n",
    "        c.append(centre)\n",
    "    return c\n",
    "\n",
    "\n",
    "def inter_dist(obj):\n",
    "    c = list_centroids(obj)\n",
    "    dis = []\n",
    "    st = []\n",
    "    for i in range(0, len(c)):\n",
    "        for j in range(i + 1, len(c)):\n",
    "            # st.append(\"Distance b/w object \"+str(i)+\" and object \"+str(j))\n",
    "            # st.append(\"D(\"+str(i)+\",\"+str(j)+\")\")\n",
    "            dis.append(math.dist(c[i], c[j]))\n",
    "    # return st,dis\n",
    "    return dis\n",
    "\n",
    "\n",
    "def focal_len_to_px(focal_len, sensor_px):\n",
    "    return round((focal_len / sensor_px) * 1000)\n",
    "\n",
    "\n",
    "def camera_to_obj_dist(focal_length_px, obj, real_width):\n",
    "    widths = list_widths(obj)\n",
    "    dists = []\n",
    "    for w in widths:\n",
    "        distance = (real_width * focal_length_px) / w\n",
    "        dists.append(distance)\n",
    "\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0],\n",
    "        pos_points[:, 1],\n",
    "        color=\"green\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0],\n",
    "        neg_points[:, 1],\n",
    "        color=\"red\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(\n",
    "        plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2)\n",
    "    )\n",
    "\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones(\n",
    "        (sorted_anns[0][\"segmentation\"].shape[0], sorted_anns[0][\"segmentation\"].shape[1], 4)\n",
    "    )\n",
    "    img[:, :, 3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann[\"segmentation\"]\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)\n",
    "\n",
    "def combine_mask(image:np.ndarray, mask:np.ndarray, color:tuple=None):\n",
    "    if color == None:\n",
    "        color = (30, 144, 255)\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h,w)\n",
    "    image[mask_image] = color\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# Object Segmentation with SAM...\n",
    "\n",
    "\n",
    "def get_mask_area(mask: np.ndarray):\n",
    "    area = mask.sum()  # assumes binary mask (True == 1)\n",
    "    return area\n",
    "\n",
    "\n",
    "def calculateIoU(gtMask, predMask):\n",
    "    # Calculate the true positives,\n",
    "    # false positives, and false negatives\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(gtMask.shape[0]):\n",
    "        for j in range(gtMask.shape[1]):\n",
    "            if gtMask[i][j] == 1 and predMask[i][j] == 1:\n",
    "                tp += 1\n",
    "            elif gtMask[i][j] == 0 and predMask[i][j] == 1:\n",
    "                fp += 1\n",
    "            elif gtMask[i][j] == 1 and predMask[i][j] == 0:\n",
    "                fn += 1\n",
    "    # Calculate IoU\n",
    "    iou = tp / (tp + fp + fn)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def segment_with_prompts(sam_model: Sam, image: np.ndarray, **kwargs):\n",
    "    h, w, _ = image.shape\n",
    "    points = kwargs.get(\n",
    "        \"points\", np.array([[w * 0.5, h * 0.5], [0, h], [w, 0], [0, 0], [w, h]])\n",
    "    )\n",
    "    labels = kwargs.get(\"labels\", np.array([1, 0, 0, 0, 0]))\n",
    "    mask = kwargs.get(\"mask\", None)\n",
    "    if mask != None:\n",
    "      mask = st.resize(mask, (256, 256), order=0, preserve_range=True, anti_aliasing=False)\n",
    "      mask = np.stack((mask,) * 1, axis=0)\n",
    "    predictor = SamPredictor(sam_model)\n",
    "    predictor.set_image(image)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=points, point_labels=labels, mask_input=mask, multimask_output=False\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def load_sam_model(\n",
    "    sam_checkpoint: str = \"sam_vit_h_4b8939.pth\",\n",
    "    model_type: str = \"vit_h\",\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    sam.to(device=device)\n",
    "    return sam\n",
    "\n",
    "def segment_everything(sam_model:Sam, image:np.ndarray, **kwargs):\n",
    "    mask = kwargs[\"mask\"]\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam_model)\n",
    "    masks = mask_generator.generate(image)\n",
    "    if mask == None:\n",
    "        return masks\n",
    "    sorted_anns = sorted(masks, key=(lambda x: x['area']), reverse=True)\n",
    "    best = -1.0\n",
    "    ind = -100\n",
    "\n",
    "    area1 = get_mask_area(mask.astype(int))\n",
    "    for i in range(10):\n",
    "        val = calculateIoU(mask.astype(int), sorted_anns[i]['segmentation'].astype(int))\n",
    "        area2 = get_mask_area(sorted_anns[i]['segmentation'].astype(int))\n",
    "        dif = abs(area2 - area1)\n",
    "        if val > best and dif < 5000:\n",
    "            ind = i\n",
    "            best = val\n",
    "        elif val > best:\n",
    "            ind = i\n",
    "            best = val\n",
    "    return sorted_anns[ind]\n",
    "\n",
    "def segment(sam_model:Sam, image:np.ndarray, seg_function=segment_with_prompts, **kwargs):\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  mask_fname = kwargs.get(\"mask_path\", None)\n",
    "  mask = None\n",
    "  if mask_fname != None:\n",
    "    mask = cv2.imread(mask_fname)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "    mask = mask.astype(bool)\n",
    "  h,w,_ = image.shape\n",
    "  points = kwargs.get(\n",
    "        \"points\", np.array([[w * 0.5, h * 0.5], [0, h], [w, 0], [0, 0], [w, h]])\n",
    "  )\n",
    "  labels = kwargs.get(\"labels\", np.array([1, 0, 0, 0, 0]))\n",
    "\n",
    "  masks = seg_function(sam_model, image, mask=mask, points=points, labels=labels)\n",
    "  return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def get_points(yolo, \n",
    "    img: Union[str, np.ndarray],\n",
    "    draw_bbox: bool = False,\n",
    "    return_img: bool = False,\n",
    "    stream: bool = True,\n",
    "):\n",
    "    result = detect_objects(model=yolo, img=img, stream=stream, draw_bbox=draw_bbox)\n",
    "    points = []\n",
    "    labels = []\n",
    "    for box in result[0][\"boxes\"]:\n",
    "        x1, y1, x2, y2 = box[:4]\n",
    "        mid_x = int(x1 + ((x2 - x1) / 2))\n",
    "        mid_y = int(y1 + ((y2 - y1) / 2))\n",
    "        points.append([mid_x, mid_y])\n",
    "        labels.append(1)  #\n",
    "    if return_img:\n",
    "        return result[0][\"img\"], result[0][\"boxes\"], points, labels\n",
    "    return result[0][\"boxes\"], points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# Extract direction and speed from the selected objects using RAFT (optical flow algorithm)..\n",
    "\n",
    "\n",
    "def display_direction(result: np.ndarray, mean_u, mean_v, points):\n",
    "    h_rat = 10\n",
    "    w_rat = 10\n",
    "    image_arr = cv2.arrowedLine(\n",
    "        img=result,\n",
    "        pt1=(points[0], points[1]),\n",
    "        pt2=(points[0] + int(mean_u) * w_rat, points[1] + int(mean_v) * h_rat),\n",
    "        color=(0, 0, 255),\n",
    "        thickness=5,\n",
    "        line_type=8,\n",
    "        tipLength=0.5,\n",
    "    )\n",
    "    return image_arr\n",
    "\n",
    "\n",
    "def get_velocity(\n",
    "    img1: str,\n",
    "    img2: str,\n",
    "    boxes: list,\n",
    "    res: np.ndarray,\n",
    "    model=None,\n",
    "    save_img: bool = True,\n",
    "    out_dir: str = \"./frames/\",\n",
    "    config_file: str = \"raft_8x2_50k_kitti2015_288x960.py\",\n",
    "    checkpoint_file: str = \"raft_8x2_50k_kitti2015_288x960.pth\",\n",
    "    device: str = \"cpu\",\n",
    "):\n",
    "    if model == None:\n",
    "        model = init_model(config_file, checkpoint_file, device=device)\n",
    "    result = inference_model(model, img1, img2)\n",
    "    img = res\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box[:4]\n",
    "        mid_x = int(x1 + ((x2 - x1) / 2))\n",
    "        mid_y = int(y1 + ((y2 - y1) / 2))\n",
    "        flows_u = result[int(y1) : int(y2), int(x1) : int(x2), 0]\n",
    "        flows_v = result[int(y1) : int(y2), int(x1) : int(x2), 1]\n",
    "        mean_u = flows_u.mean()\n",
    "        mean_v = flows_v.mean()\n",
    "        img = display_direction(img, mean_u, mean_v, (mid_x, mid_y))\n",
    "        flow_map = visualize_flow(result, save_file=\"flow_map.png\")\n",
    "        vel = math.sqrt(pow(mean_u, 2) + (pow(mean_v, 2)))\n",
    "    if save_img:\n",
    "        cv2.imwrite(\"arrow_and_box.png\", img)\n",
    "    return vel, img, flow_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 6 persons, 6 cars, 2 handbags, 1848.0ms\n",
      "Speed: 3.6ms preprocess, 1848.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Get points, boxes after detecting the object..(Using the get_points function)\n",
    "# Pass the result to the new function get_direction..\n",
    "    # The get_direction will load the RAFT model and uses the bix coordinates to find the average direction and returns the flow_map..\n",
    "    # If visulize=True, flow_map is passed to the display_direction function as well as the points and boxes coordinates..\n",
    "    # Calculate the speed of the object..\n",
    "    # Returns the flow_map and the speed and saves the image returned from the display_direction function and flow_map image..    \n",
    "\n",
    "# yolo = load_obj_model()\n",
    "# img = cv2.imread('sample_1.jpg')\n",
    "# img, boxes, points, labels = get_points(yolo = yolo, img = img, draw_bbox=True, return_img = True)\n",
    "# print(boxes)\n",
    "# cv2.imwrite('result.png', img)\n",
    "# vel, img, _ = get_velocity(boxes = boxes, img1 = 'frame51.jpg', img2 = 'frame52.jpg', res = img)\n",
    "# sam = load_sam_model(device=\"cpu\")\n",
    "# masks = segment(sam_model=sam, image=img, points=np.array(points), labels=np.array(labels))\n",
    "# print(masks.shape)\n",
    "# print(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(img)\n",
    "# show_points(np.array(points), np.array(labels), plt.gca())\n",
    "# show_mask(masks, plt.gca())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# with segment_with_prompts..\n",
    "\n",
    "\n",
    "# frame_dir = 'frames'\n",
    "# frames = os.listdir(frame_dir)\n",
    "# for frame in frames[:5]:\n",
    "#   image = cv2.imread(f'{frame_dir}/{frame}')\n",
    "#   sam = load_sam_model()\n",
    "#   mask_2 = segment(sam_model=sam, image=image, seg_function = segment_with_prompts)\n",
    "#   plt.figure(figsize=(10,10))\n",
    "#   plt.imshow(image)\n",
    "#   show_mask(mask_2, plt.gca())\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# with segment_everything..\n",
    "\n",
    "# frame_dir = 'frames'\n",
    "# frames = os.listdir(frame_dir)\n",
    "# # print(frames)\n",
    "# for frame in frames[:5]:\n",
    "#   image = cv2.imread(f'{frame_dir}/{frame}')\n",
    "#   sam = load_sam_model()\n",
    "#   mask_3 = segment(sam_model=sam, image=image, seg_function = segment_everything)\n",
    "#   plt.figure(figsize=(10,10))\n",
    "#   plt.imshow(image)\n",
    "#   show_mask(mask_3, plt.gca())\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Clone the repository:\n",
    "# !git clone https://github.com/gaomingqi/Track-Anything.git\n",
    "# %cd /content/Track-Anything\n",
    "\n",
    "# Install dependencies:\n",
    "# !pip install -r requirements.txt\n",
    "# new libraries: progressbar2 gdown gitpython openmim av hickle tqdm psutil gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Object tracking with TAN..\n",
    "\n",
    "# download checkpoints\n",
    "def download_checkpoint(url, folder, filename):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"download checkpoints ......\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "        print(\"download successfully!\")\n",
    "\n",
    "    return filepath\n",
    "\n",
    "def download_checkpoint_from_google_drive(file_id, folder, filename):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"Downloading checkpoints from Google Drive... tips: If you cannot see the progress bar, please try to download it manuall \\\n",
    "              and put it in the checkpointes directory. E2FGVI-HQ-CVPR22.pth: https://github.com/MCG-NKU/E2FGVI(E2FGVI-HQ model)\")\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        gdown.download(url, filepath, quiet=False)\n",
    "        print(\"Downloaded successfully!\")\n",
    "\n",
    "    return filepath\n",
    "\n",
    "# generate video after vos inference\n",
    "def generate_video_from_frames(frames:list, output_path:str, fps:int=30):\n",
    "    \"\"\"\n",
    "    Generates a video from a list of frames.\n",
    "\n",
    "    Args:\n",
    "        frames (list of numpy arrays): The frames to include in the video.\n",
    "        output_path (str): The path to save the generated video.\n",
    "        fps (int, optional): The frame rate of the output video. Defaults to 30.\n",
    "    \"\"\"\n",
    "    # height, width, layers = frames[0].shape\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    # video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    # print(output_path)\n",
    "    # for frame in frames:\n",
    "    #     video.write(frame)\n",
    "\n",
    "    # video.release()\n",
    "    frames = torch.from_numpy(np.asarray(frames))\n",
    "    if not os.path.exists(os.path.dirname(output_path)):\n",
    "        os.makedirs(os.path.dirname(output_path))\n",
    "    torchvision.io.write_video(output_path, frames, fps=fps, video_codec=\"libx264\")\n",
    "    return output_path\n",
    "\n",
    "def generate_frames_from_video(video_path:str, start_time:int):\n",
    "  frames = []\n",
    "  try:\n",
    "      cap = cv2.VideoCapture(video_path)\n",
    "      cap.set(cv2.CAP_PROP_POS_MSEC, start_time*1000)\n",
    "      fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "      while cap.isOpened():\n",
    "          ret, frame = cap.read()\n",
    "          if ret == True:\n",
    "              frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "          else:\n",
    "              break\n",
    "  except (OSError, TypeError, ValueError, KeyError, SyntaxError) as e:\n",
    "      print(\"read_frame_source:{} error. {}\\n\".format(video_path, str(e)))\n",
    "  return frames\n",
    "\n",
    "def track_object(images:list, points:np.ndarray, labels:np.ndarray, e2fgvi_checkpoint:str, sam_checkpoint:str, xmem_checkpoint:str, **kwargs):\n",
    "  sys.argv = [\"cuda:0\"]\n",
    "  args = parse_augment()\n",
    "  multimask = kwargs.get('multimask', True)\n",
    "  track_model = TrackingAnything(sam_checkpoint, xmem_checkpoint, e2fgvi_checkpoint, args)\n",
    "  track_model.samcontroler.sam_controler.reset_image()\n",
    "  track_model.samcontroler.sam_controler.set_image(images[0])\n",
    "  mask,_,_ = track_model.first_frame_click(image = images[0], points = points, labels = labels, multimask = multimask)\n",
    "  masks, logits ,painted_images= track_model.generator(images, mask)\n",
    "  return masks, logits, painted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# check and download checkpoints if needed\n",
    "SAM_checkpoint_dict = {\n",
    "    'vit_h': \"sam_vit_h_4b8939.pth\",\n",
    "    'vit_l': \"sam_vit_l_0b3195.pth\",\n",
    "    \"vit_b\": \"sam_vit_b_01ec64.pth\"\n",
    "}\n",
    "SAM_checkpoint_url_dict = {\n",
    "    'vit_h': \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
    "    'vit_l': \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\",\n",
    "    'vit_b': \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "}\n",
    "sam_checkpoint = SAM_checkpoint_dict['vit_h']\n",
    "sam_checkpoint_url = SAM_checkpoint_url_dict['vit_h']\n",
    "xmem_checkpoint = \"XMem-s012.pth\"\n",
    "xmem_checkpoint_url = \"https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem-s012.pth\"\n",
    "e2fgvi_checkpoint = \"E2FGVI-HQ-CVPR22.pth\"\n",
    "e2fgvi_checkpoint_id = \"10wGdKSUOie0XmCr8SQ2A2FeDe-mfn5w3\"\n",
    "\n",
    "folder = \"./checkpoints\"\n",
    "sam_checkpoint = download_checkpoint(sam_checkpoint_url, folder, sam_checkpoint)\n",
    "xmem_checkpoint = download_checkpoint(xmem_checkpoint_url, folder, xmem_checkpoint)\n",
    "e2fgvi_checkpoint = download_checkpoint_from_google_drive(e2fgvi_checkpoint_id, folder, e2fgvi_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# extract frames from the video...\n",
    "frames = generate_frames_from_video('vid_shorts.mp4', start_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "h, w, _ = frames[0].shape\n",
    "points=np.array([[int(w*0.5), int(h*0.5)], [0, h-10], [w-10, 0], [0,0], [w-10,h-10]])\n",
    "labels = np.array([1, 0, 0, 0, 0])\n",
    "# Track the masked object using point prompt..\n",
    "masks, logits, painted_images = track_object(frames, points = points, labels = labels, e2fgvi_checkpoint = e2fgvi_checkpoint, sam_checkpoint = sam_checkpoint, xmem_checkpoint = xmem_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Save the return frames in the form of a video..\n",
    "output_path = 'output.mp4'\n",
    "output_path = generate_video_from_frames(frames=frames, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "img_path = \"../imgs/\"\n",
    "\n",
    "model = load_obj_model()\n",
    "objects = detect_objects(model, img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "\n",
    "objects[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
