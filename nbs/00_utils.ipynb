{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from vid_chains.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def load_obj_model(name=\"yolov8n.pt\"):\n",
    "    return YOLO(name)\n",
    "\n",
    "\n",
    "def detect_objects(model, img, stream=True, draw_bbox=False):\n",
    "    res = model(img, stream=stream)\n",
    "    if draw_bbox:\n",
    "        return [{\"boxes\": r.boxes.data.detach().cpu().tolist(), \"img\": r.plot()} for r in res]\n",
    "    return [{\"boxes\": r.boxes.data.detach().cpu().tolist(), \"img\": img} for r in res]\n",
    "\n",
    "\n",
    "def get_width(l):\n",
    "    w = l[2] - l[0]\n",
    "    return w\n",
    "\n",
    "\n",
    "def list_widths(obj):\n",
    "    w = []\n",
    "    for i in range(0, len(obj.get(\"boxes\"))):\n",
    "        l = []\n",
    "        for j in range(0, 6):\n",
    "            l.append(obj.get(\"boxes\")[i][j])\n",
    "        if (\n",
    "            l[5] == 39.0\n",
    "        ):  # very specific test case for bottles so will ignore other objects, will remove this in the future\n",
    "            width = get_width(l)\n",
    "            w.append(width)\n",
    "    return w\n",
    "\n",
    "\n",
    "def centroid(l):\n",
    "    t = []\n",
    "    cx = (l[0] + l[2]) / 2.0\n",
    "    cy = (l[1] + l[3]) / 2.0\n",
    "    t.append(cx)\n",
    "    t.append(cy)\n",
    "    return t\n",
    "\n",
    "\n",
    "def list_centroids(obj):\n",
    "    c = []\n",
    "    for i in range(0, len(obj.get(\"boxes\"))):\n",
    "        l = []\n",
    "        for j in range(0, 4):\n",
    "            l.append(obj.get(\"boxes\")[i][j])\n",
    "        centre = centroid(l)\n",
    "        c.append(centre)\n",
    "    return c\n",
    "\n",
    "\n",
    "def inter_dist(obj):\n",
    "    c = list_centroids(obj)\n",
    "    dis = []\n",
    "    st = []\n",
    "    for i in range(0, len(c)):\n",
    "        for j in range(i + 1, len(c)):\n",
    "            # st.append(\"Distance b/w object \"+str(i)+\" and object \"+str(j))\n",
    "            # st.append(\"D(\"+str(i)+\",\"+str(j)+\")\")\n",
    "            dis.append(math.dist(c[i], c[j]))\n",
    "    # return st,dis\n",
    "    return dis\n",
    "\n",
    "\n",
    "def focal_len_to_px(focal_len, sensor_px):\n",
    "    return round((focal_len / sensor_px) * 1000)\n",
    "\n",
    "\n",
    "def camera_to_obj_dist(focal_length_px, obj, real_width):\n",
    "    widths = list_widths(obj)\n",
    "    dists = []\n",
    "    for w in widths:\n",
    "        distance = (real_width * focal_length_px) / w\n",
    "        dists.append(distance)\n",
    "\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    # print(mask_image.shape)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0],\n",
    "        pos_points[:, 1],\n",
    "        color=\"green\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0],\n",
    "        neg_points[:, 1],\n",
    "        color=\"red\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(\n",
    "        plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2)\n",
    "    )\n",
    "\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones(\n",
    "        (sorted_anns[0][\"segmentation\"].shape[0], sorted_anns[0][\"segmentation\"].shape[1], 4)\n",
    "    )\n",
    "    img[:, :, 3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann[\"segmentation\"]\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# Object Segmentation with SAM...\n",
    "\n",
    "\n",
    "def get_mask_area(mask: np.ndarray):\n",
    "    area = mask.sum()  # assumes binary mask (True == 1)\n",
    "    return area\n",
    "\n",
    "\n",
    "def calculateIoU(gtMask, predMask):\n",
    "    # Calculate the true positives,\n",
    "    # false positives, and false negatives\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(gtMask.shape[0]):\n",
    "        for j in range(gtMask.shape[1]):\n",
    "            if gtMask[i][j] == 1 and predMask[i][j] == 1:\n",
    "                tp += 1\n",
    "            elif gtMask[i][j] == 0 and predMask[i][j] == 1:\n",
    "                fp += 1\n",
    "            elif gtMask[i][j] == 1 and predMask[i][j] == 0:\n",
    "                fn += 1\n",
    "    # Calculate IoU\n",
    "    iou = tp / (tp + fp + fn)\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def segment_with_prompts(sam_model: Sam, image: np.ndarray, **kwargs):\n",
    "    h, w, _ = image.shape\n",
    "    points = kwargs.get(\n",
    "        \"points\", np.array([[w * 0.5, h * 0.5], [0, h], [w, 0], [0, 0], [w, h]])\n",
    "    )\n",
    "    labels = kwargs.get(\"labels\", np.array([1, 0, 0, 0, 0]))\n",
    "    mask = kwargs.get(\"mask\", None)\n",
    "    mask = st.resize(mask, (256, 256), order=0, preserve_range=True, anti_aliasing=False)\n",
    "    mask = np.stack((mask,) * 1, axis=0)\n",
    "    predictor = SamPredictor(sam_model)\n",
    "    predictor.set_image(image)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=points, point_labels=labels, mask_input=mask, multimask_output=False\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def load_sam_model(\n",
    "    sam_checkpoint: str = \"sam_vit_h_4b8939.pth\",\n",
    "    model_type: str = \"vit_h\",\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    sam.to(device=device)\n",
    "    return sam\n",
    "\n",
    "\n",
    "def segment_everything(sam_model: Sam, image: np.ndarray, **kwargs):\n",
    "    mask = kwargs[\"mask\"]\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam_model)\n",
    "    masks = mask_generator.generate(image)\n",
    "    sorted_anns = sorted(masks, key=(lambda x: x[\"area\"]), reverse=True)\n",
    "    best = -1.0\n",
    "    ind = -100\n",
    "    area1 = get_mask_area(mask.astype(int))\n",
    "    for i in range(10):\n",
    "        val = calculateIoU(mask.astype(int), sorted_anns[i][\"segmentation\"].astype(int))\n",
    "        area2 = get_mask_area(sorted_anns[i][\"segmentation\"].astype(int))\n",
    "        dif = abs(area2 - area1)\n",
    "        if val > best and dif < 5000:\n",
    "            ind = i\n",
    "            best = val\n",
    "        elif val > best:\n",
    "            ind = i\n",
    "            best = val\n",
    "    return masks[ind]\n",
    "\n",
    "\n",
    "def segment(sam_model: Sam, image: np.ndarray, seg_function=segment_with_prompts, **kwargs):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    mask_fname = kwargs.get(\"mask_path\", \"mask.png\")\n",
    "    mask = cv2.imread(mask_fname)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "    mask = mask.astype(bool)\n",
    "    h, w, _ = image.shape\n",
    "    points = kwargs.get(\n",
    "        \"points\", np.array([[w * 0.5, h * 0.5], [0, h], [w, 0], [0, 0], [w, h]])\n",
    "    )\n",
    "    labels = kwargs.get(\"labels\", np.array([1, 0, 0, 0, 0]))\n",
    "    masks = seg_function(sam_model, image, mask=mask, points=points, labels=labels)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_points(\n",
    "    img: Union[str, np.ndarray],\n",
    "    draw_bbox: bool = False,\n",
    "    return_img: bool = False,\n",
    "    stream: bool = True,\n",
    "):\n",
    "    if isinstance(img, str):\n",
    "        img = cv2.imread(img)\n",
    "    yolo = load_obj_model()\n",
    "    result = detect_objects(model=yolo, img=img, stream=stream, draw_bbox=draw_bbox)\n",
    "    points = []\n",
    "    labels = []\n",
    "    for box in result[0][\"boxes\"]:\n",
    "        x1, y1, x2, y2 = box[:4]\n",
    "        mid_x = int(x1 + ((x2 - x1) / 2))\n",
    "        mid_y = int(y1 + ((y2 - y1) / 2))\n",
    "        points.append([[mid_x, mid_y]])\n",
    "        labels.append(1)  #\n",
    "    if return_img:\n",
    "        return result[0][\"img\"], result[0][\"boxes\"], points, labels\n",
    "    return result[0][\"boxes\"], points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "# Extract direction and speed from the selected objects using RAFT (optical flow algorithm)..\n",
    "\n",
    "\n",
    "def display_direction(result: np.ndarray, mean_u, mean_v, points):\n",
    "    h_rat = 10\n",
    "    w_rat = 10\n",
    "    image_arr = cv2.arrowedLine(\n",
    "        img=result,\n",
    "        pt1=(points[0], points[1]),\n",
    "        pt2=(points[0] + int(mean_u) * w_rat, points[1] + int(mean_v) * h_rat),\n",
    "        color=(0, 0, 255),\n",
    "        thickness=5,\n",
    "        line_type=8,\n",
    "        tipLength=0.5,\n",
    "    )\n",
    "    return image_arr\n",
    "\n",
    "\n",
    "def get_velocity(\n",
    "    img1: str,\n",
    "    img2: str,\n",
    "    boxes: list,\n",
    "    res: np.ndarray,\n",
    "    model=None,\n",
    "    save_img: bool = True,\n",
    "    out_dir: str = \"./frames/\",\n",
    "    config_file: str = \"raft_8x2_50k_kitti2015_288x960.py\",\n",
    "    checkpoint_file: str = \"raft_8x2_50k_kitti2015_288x960.pth\",\n",
    "    device: str = \"cpu\",\n",
    "):\n",
    "    if model == None:\n",
    "        model = init_model(config_file, checkpoint_file, device=device)\n",
    "    result = inference_model(model, img1, img2)\n",
    "    img = res\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box[:4]\n",
    "        mid_x = int(x1 + ((x2 - x1) / 2))\n",
    "        mid_y = int(y1 + ((y2 - y1) / 2))\n",
    "        flows_u = result[int(y1) : int(y2), int(x1) : int(x2), 0]\n",
    "        flows_v = result[int(y1) : int(y2), int(x1) : int(x2), 1]\n",
    "        mean_u = flows_u.mean()\n",
    "        mean_v = flows_v.mean()\n",
    "        img = display_direction(img, mean_u, mean_v, (mid_x, mid_y))\n",
    "        flow_map = visualize_flow(result, save_file=\"flow_map.png\")\n",
    "        vel = math.sqrt(pow(mean_u, 2) + (pow(mean_v, 2)))\n",
    "    if save_img:\n",
    "        cv2.imwrite(\"arrow_and_box.png\", img)\n",
    "    return vel, img, flow_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 train, 121.0ms\n",
      "Speed: 5.9ms preprocess, 121.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: raft_8x2_50k_kitti2015_288x960.pth\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Get points, boxes after detecting the object..(Using the get_points function)\n",
    "# Pass the result to the new function get_direction..\n",
    "# The get_direction will load the RAFT model and uses the bix coordinates to find the average direction and returns the flow_map..\n",
    "# If visulize=True, flow_map is passed to the display_direction function as well as the points and boxes coordinates..\n",
    "# Calculate the speed of the object..\n",
    "# Returns the flow_map and the speed and saves the image returned from the display_direction function and flow_map image..\n",
    "\n",
    "img, boxes, points, labels = get_points(\"frame51.jpg\", draw_bbox=True, return_img=True)\n",
    "# print(boxes)\n",
    "# cv2.imwrite('result.png', img)\n",
    "vel, img, _ = get_velocity(boxes=boxes, img1=\"frame51.jpg\", img2=\"frame52.jpg\", res=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# with segment_with_prompts..\n",
    "\n",
    "\n",
    "frame_dir = \"frames\"\n",
    "frames = os.listdir(frame_dir)\n",
    "for frame in frames[:5]:\n",
    "    image = cv2.imread(f\"{frame_dir}/{frame}\")\n",
    "    sam = load_sam_model()\n",
    "    mask_2 = segment(sam_model=sam, image=image, seg_function=segment_with_prompts)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask_2, plt.gca())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# with segment_everything..\n",
    "\n",
    "frame_dir = \"frames\"\n",
    "frames = os.listdir(frame_dir)\n",
    "# print(frames)\n",
    "for frame in frames[:5]:\n",
    "    image = cv2.imread(f\"{frame_dir}/{frame}\")\n",
    "    sam = load_sam_model()\n",
    "    mask_3 = segment(sam_model=sam, image=image, seg_function=segment_everything)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    show_mask(mask_3, plt.gca())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Clone the repository:\n",
    "# !git clone https://github.com/gaomingqi/Track-Anything.git\n",
    "# %cd /content/Track-Anything\n",
    "\n",
    "# Install dependencies:\n",
    "# !pip install -r requirements.txt\n",
    "# new libraries: progressbar2 gdown gitpython openmim av hickle tqdm psutil gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# check and download checkpoints if needed\n",
    "SAM_checkpoint_dict = {\n",
    "    \"vit_h\": \"sam_vit_h_4b8939.pth\",\n",
    "    \"vit_l\": \"sam_vit_l_0b3195.pth\",\n",
    "    \"vit_b\": \"sam_vit_b_01ec64.pth\",\n",
    "}\n",
    "SAM_checkpoint_url_dict = {\n",
    "    \"vit_h\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
    "    \"vit_l\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\",\n",
    "    \"vit_b\": \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\",\n",
    "}\n",
    "sam_checkpoint = SAM_checkpoint_dict[\"vit_h\"]\n",
    "sam_checkpoint_url = SAM_checkpoint_url_dict[\"vit_h\"]\n",
    "xmem_checkpoint = \"XMem-s012.pth\"\n",
    "xmem_checkpoint_url = \"https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem-s012.pth\"\n",
    "e2fgvi_checkpoint = \"E2FGVI-HQ-CVPR22.pth\"\n",
    "e2fgvi_checkpoint_id = \"10wGdKSUOie0XmCr8SQ2A2FeDe-mfn5w3\"\n",
    "\n",
    "folder = \"./checkpoints\"\n",
    "sam_checkpoint = download_checkpoint(sam_checkpoint_url, folder, sam_checkpoint)\n",
    "xmem_checkpoint = download_checkpoint(xmem_checkpoint_url, folder, xmem_checkpoint)\n",
    "e2fgvi_checkpoint = download_checkpoint_from_google_drive(\n",
    "    e2fgvi_checkpoint_id, folder, e2fgvi_checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# extract frames from the video...\n",
    "frames = generate_frames_from_video(\"vid_shorts.mp4\", start_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "h, w, _ = frames[0].shape\n",
    "points = np.array(\n",
    "    [[int(w * 0.5), int(h * 0.5)], [0, h - 10], [w - 10, 0], [0, 0], [w - 10, h - 10]]\n",
    ")\n",
    "labels = np.array([1, 0, 0, 0, 0])\n",
    "# Track the masked object using point prompt..\n",
    "masks, logits, painted_images = track_object(\n",
    "    frames,\n",
    "    points=points,\n",
    "    labels=labels,\n",
    "    e2fgvi_checkpoint=e2fgvi_checkpoint,\n",
    "    sam_checkpoint=sam_checkpoint,\n",
    "    xmem_checkpoint=xmem_checkpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Save the return frames in the form of a video..\n",
    "output_path = \"output.mp4\"\n",
    "output_path = generate_video_from_frames(frames=frames, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "img_path = \"../imgs/\"\n",
    "\n",
    "model = load_obj_model()\n",
    "objects = detect_objects(model, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "\n",
    "objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
