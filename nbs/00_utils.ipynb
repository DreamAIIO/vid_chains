{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from vid_chains.imports import *\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import skimage.transform as st\n",
    "import sys\n",
    "from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
    "from segment_anything.modeling import Sam\n",
    "\n",
    "import gdown\n",
    "sys.path.insert(3, os.getcwd()+\"/Track_Anything\")\n",
    "sys.path.insert(1, os.getcwd()+\"/Track_Anything/tracker\")\n",
    "sys.path.insert(2, sys.path[1]+\"/model\")\n",
    "from track_anything import TrackingAnything\n",
    "from track_anything import parse_augment\n",
    "import requests\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def load_obj_model(name=\"yolov8n.pt\"):\n",
    "    return YOLO(name)\n",
    "\n",
    "\n",
    "def detect_objects(model, img):\n",
    "    res = model(img, stream=True)\n",
    "    return [{\"boxes\": r.boxes.data.detach().cpu().tolist()} for r in res]\n",
    "\n",
    "\n",
    "def centroid(l):\n",
    "    t = []\n",
    "    cx = (l[0] + l[2]) / 2.0\n",
    "    cy = (l[1] + l[3]) / 2.0\n",
    "    t.append(cx)\n",
    "    t.append(cy)\n",
    "    return t\n",
    "\n",
    "\n",
    "def list_centroids(objects):\n",
    "    c = []\n",
    "    for i in range(0, 11):\n",
    "        l = []\n",
    "        for j in range(0, 4):\n",
    "            l.append(objects[0].get(\"boxes\")[i][j])\n",
    "        centre = centroid(l)\n",
    "        c.append(centre)\n",
    "    return c\n",
    "\n",
    "\n",
    "def inter_dist(objects):\n",
    "    c = list_centroids(objects)\n",
    "    dis = []\n",
    "    st = []\n",
    "    for i in range(0, 11):\n",
    "        for j in range(i + 1, 11):\n",
    "            # st.append(\"Distance b/w object \"+str(i)+\" and object \"+str(j))\n",
    "            # st.append(\"D(\"+str(i)+\",\"+str(j)+\")\")\n",
    "            dis.append(math.dist(c[i], c[j]))\n",
    "    # return st,dis\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    # print(mask_image.shape)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def get_mask_area(mask:np.ndarray):\n",
    "  area = mask.sum() # assumes binary mask (True == 1)\n",
    "  return area\n",
    "\n",
    "def calculateIoU(gtMask, predMask):\n",
    "        # Calculate the true positives,\n",
    "        # false positives, and false negatives\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for i in range(gtMask.shape[0]):\n",
    "            for j in range(gtMask.shape[1]):\n",
    "                if gtMask[i][j] == 1 and predMask[i][j] == 1:\n",
    "                    tp += 1\n",
    "                elif gtMask[i][j] == 0 and predMask[i][j] == 1:\n",
    "                    fp += 1\n",
    "                elif gtMask[i][j] == 1 and predMask[i][j] == 0:\n",
    "                    fn += 1\n",
    "        # Calculate IoU\n",
    "        iou = tp / (tp + fp + fn)\n",
    "\n",
    "        return iou\n",
    "\n",
    "def segment_with_prompts(sam_model:Sam, image:np.ndarray, **kwargs):\n",
    "  h,w,_ = image.shape\n",
    "  points = kwargs.get('points', np.array([[w*0.5, h*0.5], [0, h], [w, 0], [0,0], [w,h]]))\n",
    "  labels = kwargs.get('labels', np.array([1, 0, 0, 0, 0]))\n",
    "  mask = kwargs.get('mask', None)\n",
    "  mask = st.resize(mask, (256, 256), order=0, preserve_range=True, anti_aliasing=False)\n",
    "  mask = np.stack((mask,)*1, axis = 0)\n",
    "  predictor = SamPredictor(sam_model)\n",
    "  predictor.set_image(image)\n",
    "  masks, scores, logits = predictor.predict(point_coords=points, point_labels=labels, mask_input=mask, multimask_output=False)\n",
    "  return masks\n",
    "\n",
    "def load_sam_model(sam_checkpoint:str = \"sam_vit_h_4b8939.pth\", model_type:str = \"vit_h\", device:str = \"cuda\"):\n",
    "  sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "  sam.to(device=device)\n",
    "  return sam\n",
    "\n",
    "def segment_everything(sam_model:Sam, image:np.ndarray, **kwargs):\n",
    "  mask = kwargs['mask']\n",
    "  mask_generator = SamAutomaticMaskGenerator(sam_model)\n",
    "  masks = mask_generator.generate(image)\n",
    "  sorted_anns = sorted(masks, key=(lambda x: x['area']), reverse=True)\n",
    "  best = -1.0\n",
    "  ind = -100\n",
    "  area1 = get_mask_area(mask.astype(int))\n",
    "  for i in range(10):\n",
    "    val = calculateIoU(mask.astype(int), sorted_anns[i]['segmentation'].astype(int))\n",
    "    area2 = get_mask_area(sorted_anns[i]['segmentation'].astype(int))\n",
    "    dif = abs(area2 - area1)\n",
    "    if val > best and dif < 5000:\n",
    "      ind = i\n",
    "      best = val\n",
    "    elif val > best:\n",
    "      ind = i\n",
    "      best = val\n",
    "  return masks[ind]\n",
    "\n",
    "def segment(sam_model:Sam, image:np.ndarray, seg_function=segment_with_prompts, **kwargs):\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  mask_fname = kwargs.get('mask_path', 'mask.png')\n",
    "  mask = cv2.imread(mask_fname)\n",
    "  mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "  mask = mask.astype(bool)\n",
    "  h,w,_ = image.shape\n",
    "  points = kwargs.get('points', np.array([[w*0.5, h*0.5], [0, h], [w, 0], [0,0], [w,h]]))\n",
    "  labels = kwargs.get('labels', np.array([1, 0, 0, 0, 0]))\n",
    "  masks = seg_function(sam_model, image, mask=mask, points=points, labels=labels)\n",
    "  return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | expprt\n",
    "\n",
    "# download checkpoints\n",
    "def download_checkpoint(url, folder, filename):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"download checkpoints ......\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "        print(\"download successfully!\")\n",
    "\n",
    "    return filepath\n",
    "\n",
    "def download_checkpoint_from_google_drive(file_id, folder, filename):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"Downloading checkpoints from Google Drive... tips: If you cannot see the progress bar, please try to download it manuall \\\n",
    "              and put it in the checkpointes directory. E2FGVI-HQ-CVPR22.pth: https://github.com/MCG-NKU/E2FGVI(E2FGVI-HQ model)\")\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        gdown.download(url, filepath, quiet=False)\n",
    "        print(\"Downloaded successfully!\")\n",
    "\n",
    "    return filepath\n",
    "\n",
    "# generate video after vos inference\n",
    "def generate_video_from_frames(frames:list, output_path:str, fps:int=30):\n",
    "    \"\"\"\n",
    "    Generates a video from a list of frames.\n",
    "\n",
    "    Args:\n",
    "        frames (list of numpy arrays): The frames to include in the video.\n",
    "        output_path (str): The path to save the generated video.\n",
    "        fps (int, optional): The frame rate of the output video. Defaults to 30.\n",
    "    \"\"\"\n",
    "    # height, width, layers = frames[0].shape\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    # video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    # print(output_path)\n",
    "    # for frame in frames:\n",
    "    #     video.write(frame)\n",
    "\n",
    "    # video.release()\n",
    "    frames = torch.from_numpy(np.asarray(frames))\n",
    "    if not os.path.exists(os.path.dirname(output_path)):\n",
    "        os.makedirs(os.path.dirname(output_path))\n",
    "    torchvision.io.write_video(output_path, frames, fps=fps, video_codec=\"libx264\")\n",
    "    return output_path\n",
    "\n",
    "def generate_frames_from_video(video_path:str, start_time:int):\n",
    "  frames = []\n",
    "  try:\n",
    "      cap = cv2.VideoCapture(video_path)\n",
    "      cap.set(cv2.CAP_PROP_POS_MSEC, start_time*1000)\n",
    "      fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "      while cap.isOpened():\n",
    "          ret, frame = cap.read()\n",
    "          if ret == True:\n",
    "              frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "          else:\n",
    "              break\n",
    "  except (OSError, TypeError, ValueError, KeyError, SyntaxError) as e:\n",
    "      print(\"read_frame_source:{} error. {}\\n\".format(video_path, str(e)))\n",
    "  return frames\n",
    "\n",
    "def track_object(images:list, points:np.ndarray, labels:np.ndarray, e2fgvi_checkpoint:str, sam_checkpoint:str, xmem_checkpoint:str, **kwargs):\n",
    "  sys.argv = [\"cuda:0\"]\n",
    "  args = parse_augment()\n",
    "  multimask = kwargs.get('multimask', True)\n",
    "  track_model = TrackingAnything(sam_checkpoint, xmem_checkpoint, e2fgvi_checkpoint, args)\n",
    "  track_model.samcontroler.sam_controler.reset_image()\n",
    "  track_model.samcontroler.sam_controler.set_image(images[0])\n",
    "  mask,_,_ = track_model.first_frame_click(image = images[0], points = points, labels = labels, multimask = multimask)\n",
    "  masks, logits ,painted_images= track_model.generator(images, mask)\n",
    "  return masks, logits, painted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "\n",
    "def get_points(img:np.ndarray):\n",
    "    yolo = load_obj_model()\n",
    "    img = cv2.imread()\n",
    "    boxes = detect_objects(img, yolo)\n",
    "    points = []\n",
    "    labels = []\n",
    "    for box in boxes['boxes']:\n",
    "        x1, y1, x2, y2 = box\n",
    "        mid_x = int(x1+((x2-x1)/2))\n",
    "        mid_y = int(y1+((y2-y1)/2))\n",
    "        points.append(mid_x, mid_y)\n",
    "        labels.append(1)\n",
    "    return points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# with segment_with_prompts..\n",
    "\n",
    "\n",
    "frame_dir = 'frames'\n",
    "frames = os.listdir(frame_dir)\n",
    "for frame in frames[:5]:\n",
    "  image = cv2.imread(f'{frame_dir}/{frame}')\n",
    "  sam = load_sam_model()\n",
    "  mask_2 = segment(sam_model=sam, image=image, seg_function = segment_with_prompts)\n",
    "  plt.figure(figsize=(10,10))\n",
    "  plt.imshow(image)\n",
    "  show_mask(mask_2, plt.gca())\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# with segment_everything..\n",
    "\n",
    "frame_dir = 'frames'\n",
    "frames = os.listdir(frame_dir)\n",
    "# print(frames)\n",
    "for frame in frames[:5]:\n",
    "  image = cv2.imread(f'{frame_dir}/{frame}')\n",
    "  sam = load_sam_model()\n",
    "  mask_3 = segment(sam_model=sam, image=image, seg_function = segment_everything)\n",
    "  plt.figure(figsize=(10,10))\n",
    "  plt.imshow(image)\n",
    "  show_mask(mask_3, plt.gca())\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Clone the repository:\n",
    "# !git clone https://github.com/gaomingqi/Track-Anything.git\n",
    "# %cd /content/Track-Anything\n",
    "\n",
    "# Install dependencies:\n",
    "# !pip install -r requirements.txt\n",
    "# new libraries: progressbar2 gdown gitpython openmim av hickle tqdm psutil gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# check and download checkpoints if needed\n",
    "SAM_checkpoint_dict = {\n",
    "    'vit_h': \"sam_vit_h_4b8939.pth\",\n",
    "    'vit_l': \"sam_vit_l_0b3195.pth\",\n",
    "    \"vit_b\": \"sam_vit_b_01ec64.pth\"\n",
    "}\n",
    "SAM_checkpoint_url_dict = {\n",
    "    'vit_h': \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\",\n",
    "    'vit_l': \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\",\n",
    "    'vit_b': \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
    "}\n",
    "sam_checkpoint = SAM_checkpoint_dict['vit_h']\n",
    "sam_checkpoint_url = SAM_checkpoint_url_dict['vit_h']\n",
    "xmem_checkpoint = \"XMem-s012.pth\"\n",
    "xmem_checkpoint_url = \"https://github.com/hkchengrex/XMem/releases/download/v1.0/XMem-s012.pth\"\n",
    "e2fgvi_checkpoint = \"E2FGVI-HQ-CVPR22.pth\"\n",
    "e2fgvi_checkpoint_id = \"10wGdKSUOie0XmCr8SQ2A2FeDe-mfn5w3\"\n",
    "\n",
    "folder = \"./checkpoints\"\n",
    "sam_checkpoint = download_checkpoint(sam_checkpoint_url, folder, sam_checkpoint)\n",
    "xmem_checkpoint = download_checkpoint(xmem_checkpoint_url, folder, xmem_checkpoint)\n",
    "e2fgvi_checkpoint = download_checkpoint_from_google_drive(e2fgvi_checkpoint_id, folder, e2fgvi_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# extract frames from the video...\n",
    "frames = generate_frames_from_video('vid_shorts.mp4', start_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "h, w, _ = frames[0].shape\n",
    "points=np.array([[int(w*0.5), int(h*0.5)], [0, h-10], [w-10, 0], [0,0], [w-10,h-10]])\n",
    "labels = np.array([1, 0, 0, 0, 0])\n",
    "# Track the masked object using point prompt..\n",
    "masks, logits, painted_images = track_object(frames, points = points, labels = labels, e2fgvi_checkpoint = e2fgvi_checkpoint, sam_checkpoint = sam_checkpoint, xmem_checkpoint = xmem_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "# Save the return frames in the form of a video..\n",
    "output_path = 'output.mp4'\n",
    "output_path = generate_video_from_frames(frames=frames, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "img_path = \"../imgs/\"\n",
    "\n",
    "model = load_obj_model()\n",
    "objects = detect_objects(model, img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | eval: false\n",
    "\n",
    "\n",
    "objects[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
