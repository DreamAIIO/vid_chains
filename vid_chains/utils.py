# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_utils.ipynb.

# %% auto 0
__all__ = ['load_obj_model', 'detect_objects', 'get_width', 'list_widths', 'centroid', 'list_centroids', 'inter_dist',
           'focal_len_to_px', 'camera_to_obj_dist', 'show_mask', 'show_points', 'show_box', 'show_anns', 'combine_mask',
           'get_mask_area', 'calculateIoU', 'segment_with_prompts', 'load_sam_model', 'segment_everything', 'segment',
           'get_points', 'display_direction', 'get_velocity']

# %% ../nbs/00_utils.ipynb 2
from .imports import *

# %% ../nbs/00_utils.ipynb 4
def load_obj_model(name="yolov8n.pt"):
    return YOLO(name)


def detect_objects(model, img, stream=True, draw_bbox=False):
    res = model(img, stream=stream)
    if draw_bbox:
        return [{"boxes": r.boxes.data.detach().cpu().tolist(), "img": r.plot()} for r in res]
    return [{"boxes": r.boxes.data.detach().cpu().tolist(), "img": img} for r in res]


def get_width(l):
    w = l[2] - l[0]
    return w


def list_widths(obj):
    w = []
    for i in range(0, len(obj.get("boxes"))):
        l = []
        for j in range(0, 6):
            l.append(obj.get("boxes")[i][j])
        if (
            l[5] == 39.0
        ):  # very specific test case for bottles so will ignore other objects, will remove this in the future
            width = get_width(l)
            w.append(width)
    return w


def centroid(l):
    t = []
    cx = (l[0] + l[2]) / 2.0
    cy = (l[1] + l[3]) / 2.0
    t.append(cx)
    t.append(cy)
    return t


def list_centroids(obj):
    c = []
    for i in range(0, len(obj.get("boxes"))):
        l = []
        for j in range(0, 4):
            l.append(obj.get("boxes")[i][j])
        centre = centroid(l)
        c.append(centre)
    return c


def inter_dist(obj):
    c = list_centroids(obj)
    dis = []
    st = []
    for i in range(0, len(c)):
        for j in range(i + 1, len(c)):
            # st.append("Distance b/w object "+str(i)+" and object "+str(j))
            # st.append("D("+str(i)+","+str(j)+")")
            dis.append(math.dist(c[i], c[j]))
    # return st,dis
    return dis


def focal_len_to_px(focal_len, sensor_px):
    return round((focal_len / sensor_px) * 1000)


def camera_to_obj_dist(focal_length_px, obj, real_width):
    widths = list_widths(obj)
    dists = []
    for w in widths:
        distance = (real_width * focal_length_px) / w
        dists.append(distance)

    return dists

# %% ../nbs/00_utils.ipynb 5
def show_mask(mask, ax, random_color=False):
    if random_color:
        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)
    else:
        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)
    ax.imshow(mask_image)


def show_points(coords, labels, ax, marker_size=375):
    pos_points = coords[labels == 1]
    neg_points = coords[labels == 0]
    ax.scatter(
        pos_points[:, 0],
        pos_points[:, 1],
        color="green",
        marker="*",
        s=marker_size,
        edgecolor="white",
        linewidth=1.25,
    )
    ax.scatter(
        neg_points[:, 0],
        neg_points[:, 1],
        color="red",
        marker="*",
        s=marker_size,
        edgecolor="white",
        linewidth=1.25,
    )


def show_box(box, ax):
    x0, y0 = box[0], box[1]
    w, h = box[2] - box[0], box[3] - box[1]
    ax.add_patch(
        plt.Rectangle((x0, y0), w, h, edgecolor="green", facecolor=(0, 0, 0, 0), lw=2)
    )


def show_anns(anns):
    if len(anns) == 0:
        return
    sorted_anns = sorted(anns, key=(lambda x: x["area"]), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)

    img = np.ones(
        (sorted_anns[0]["segmentation"].shape[0], sorted_anns[0]["segmentation"].shape[1], 4)
    )
    img[:, :, 3] = 0
    for ann in sorted_anns:
        m = ann["segmentation"]
        color_mask = np.concatenate([np.random.random(3), [0.35]])
        img[m] = color_mask
    ax.imshow(img)

def combine_mask(image:np.ndarray, mask:np.ndarray, color:tuple=None):
    if color == None:
        color = (30, 144, 255)
    h, w = mask.shape[-2:]
    mask_image = mask.reshape(h,w)
    image[mask_image] = color
    return image

# %% ../nbs/00_utils.ipynb 6
# Object Segmentation with SAM...


def get_mask_area(mask: np.ndarray):
    area = mask.sum()  # assumes binary mask (True == 1)
    return area


def calculateIoU(gtMask, predMask):
    # Calculate the true positives,
    # false positives, and false negatives
    tp = 0
    fp = 0
    fn = 0

    for i in range(gtMask.shape[0]):
        for j in range(gtMask.shape[1]):
            if gtMask[i][j] == 1 and predMask[i][j] == 1:
                tp += 1
            elif gtMask[i][j] == 0 and predMask[i][j] == 1:
                fp += 1
            elif gtMask[i][j] == 1 and predMask[i][j] == 0:
                fn += 1
    # Calculate IoU
    iou = tp / (tp + fp + fn)

    return iou


def segment_with_prompts(sam_model: Sam, image: np.ndarray, **kwargs):
    h, w, _ = image.shape
    points = kwargs.get(
        "points", np.array([[w * 0.5, h * 0.5], [0, h], [w, 0], [0, 0], [w, h]])
    )
    labels = kwargs.get("labels", np.array([1, 0, 0, 0, 0]))
    mask = kwargs.get("mask", None)
    if mask != None:
      mask = st.resize(mask, (256, 256), order=0, preserve_range=True, anti_aliasing=False)
      mask = np.stack((mask,) * 1, axis=0)
    predictor = SamPredictor(sam_model)
    predictor.set_image(image)
    masks, scores, logits = predictor.predict(
        point_coords=points, point_labels=labels, mask_input=mask, multimask_output=False
    )
    return masks


def load_sam_model(
    sam_checkpoint: str = "sam_vit_h_4b8939.pth",
    model_type: str = "vit_h",
    device: str = "cuda",
):
    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
    sam.to(device=device)
    return sam

def segment_everything(sam_model:Sam, image:np.ndarray, **kwargs):
    mask = kwargs["mask"]
    mask_generator = SamAutomaticMaskGenerator(sam_model)
    masks = mask_generator.generate(image)
    if mask == None:
        return masks
    sorted_anns = sorted(masks, key=(lambda x: x['area']), reverse=True)
    best = -1.0
    ind = -100

    area1 = get_mask_area(mask.astype(int))
    for i in range(10):
        val = calculateIoU(mask.astype(int), sorted_anns[i]['segmentation'].astype(int))
        area2 = get_mask_area(sorted_anns[i]['segmentation'].astype(int))
        dif = abs(area2 - area1)
        if val > best and dif < 5000:
            ind = i
            best = val
        elif val > best:
            ind = i
            best = val
    return sorted_anns[ind]

def segment(sam_model:Sam, image:np.ndarray, seg_function=segment_with_prompts, **kwargs):
  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
  mask_fname = kwargs.get("mask_path", None)
  mask = None
  if mask_fname != None:
    mask = cv2.imread(mask_fname)
    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)
    mask = mask.astype(bool)
  h,w,_ = image.shape
  points = kwargs.get(
        "points", np.array([[w * 0.5, h * 0.5], [0, h], [w, 0], [0, 0], [w, h]])
  )
  labels = kwargs.get("labels", np.array([1, 0, 0, 0, 0]))

  masks = seg_function(sam_model, image, mask=mask, points=points, labels=labels)
  return masks

# %% ../nbs/00_utils.ipynb 7
def get_points(yolo, 
    img: Union[str, np.ndarray],
    draw_bbox: bool = False,
    return_img: bool = False,
    stream: bool = True,
):
    result = detect_objects(model=yolo, img=img, stream=stream, draw_bbox=draw_bbox)
    points = []
    labels = []
    for box in result[0]["boxes"]:
        x1, y1, x2, y2 = box[:4]
        mid_x = int(x1 + ((x2 - x1) / 2))
        mid_y = int(y1 + ((y2 - y1) / 2))
        points.append([mid_x, mid_y])
        labels.append(1)  #
    if return_img:
        return result[0]["img"], result[0]["boxes"], points, labels
    return result[0]["boxes"], points, labels

# %% ../nbs/00_utils.ipynb 8
# Extract direction and speed from the selected objects using RAFT (optical flow algorithm)..


def display_direction(result: np.ndarray, mean_u, mean_v, points):
    h_rat = 10
    w_rat = 10
    image_arr = cv2.arrowedLine(
        img=result,
        pt1=(points[0], points[1]),
        pt2=(points[0] + int(mean_u) * w_rat, points[1] + int(mean_v) * h_rat),
        color=(0, 0, 255),
        thickness=5,
        line_type=8,
        tipLength=0.5,
    )
    return image_arr


def get_velocity(
    img1: str,
    img2: str,
    boxes: list,
    res: np.ndarray,
    model=None,
    save_img: bool = True,
    out_dir: str = "./frames/",
    config_file: str = "raft_8x2_50k_kitti2015_288x960.py",
    checkpoint_file: str = "raft_8x2_50k_kitti2015_288x960.pth",
    device: str = "cpu",
):
    if model == None:
        model = init_model(config_file, checkpoint_file, device=device)
    result = inference_model(model, img1, img2)
    img = res
    for box in boxes:
        x1, y1, x2, y2 = box[:4]
        mid_x = int(x1 + ((x2 - x1) / 2))
        mid_y = int(y1 + ((y2 - y1) / 2))
        flows_u = result[int(y1) : int(y2), int(x1) : int(x2), 0]
        flows_v = result[int(y1) : int(y2), int(x1) : int(x2), 1]
        mean_u = flows_u.mean()
        mean_v = flows_v.mean()
        img = display_direction(img, mean_u, mean_v, (mid_x, mid_y))
        flow_map = visualize_flow(result, save_file="flow_map.png")
        vel = math.sqrt(pow(mean_u, 2) + (pow(mean_v, 2)))
    if save_img:
        cv2.imwrite("arrow_and_box.png", img)
    return vel, img, flow_map
